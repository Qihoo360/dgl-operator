#!/bin/bash
POSITIONAL=()
while [[ $# -gt 0 ]]
do
key="$1"

case $key in
    --mix-cpus-and-single-gpu)
    MIX_CPUS_SINGLE_GPU=true
    shift
    ;;
    --num-partitions)
    PARTITIONS="$2"
    shift
    shift
    ;;
    --worksapce)
    WORKSPACE="$2"
    shift
    shift
    ;;
    --dataset)
    DATASET="$2"
    shift
    shift
    ;;
    --custom-dataset)
    CUSTOM_DATASET=true
    shift
    ;;
    --ignore-partition)
    IGNORE_PARTITION=true
    shift
    ;;
    --partitioned-dataset-dir)
    PARTITIONED_DATASET_DIR="$2"
    shift
    shift
    ;;
    --launch-entry-point)
    LAUNCH_ENTRY_POINT="$2"
    shift
    shift
    ;;
    --dataset-format)
    DATASET_FORMAT="$2"
    shift
    shift
    ;;
    --dataset-files)
    DATASET_FILES="$2"
    shift
    shift
    ;;
    --dispatch-entry-point)
    DISPATCH_ENTRY_POINT="$2"
    shift
    shift
    ;;
    --partition-config-path)
    LAUNCHER_CONFIG_PATH="$2"
    shift
    shift
    ;;
    --pvc-partitioned-dir)
    PVC_PARTITIONED_DIR="$2"
    shift
    shift
    ;;
    --num-servers)
    SERVERS="$2"
    shift
    shift
    ;;
    --revise-hostfile-entry-point)
    REVISE_HOSTFILE_ENTRY_POINT="$2"
    shift
    shift
    ;;
    --model)
    MODEL_NAME="$2"
    shift
    shift
    ;;
    --num-client-proc)
    CLIENT_PROCS="$2"
    shift
    shift
    ;;
    --save-path)
    SAVE_PATH="$2"
    shift
    shift
    ;;
    *)
    POSITIONAL+=("$1")
    shift
    ;;
esac
done
set -- "${POSITIONAL[@]}" # restore positional parameters

# set default value
if [ -z ${WORKSPACE+x} ]; then WORKSPACE="/dgl_workspace"; fi
if [ -z ${DATASET+x} ]; then DATASET="FB15k"; fi
if [ -z ${LAUNCH_ENTRY_POINT+x} ]; then LAUNCH_ENTRY_POINT="tools/launch.py"; fi
if [ -z ${DISPATCH_ENTRY_POINT+x} ]; then DISPATCH_ENTRY_POINT="tools/dispatch.py"; fi
if [ -z ${REVISE_HOSTFILE_ENTRY_POINT+x} ]; then REVISE_HOSTFILE_ENTRY_POINT="tools/revise_hostfile.py"; fi
if [ -z ${SERVERS+x} ]; then SERVERS="1"; fi
if [ -z ${CLIENT_PROCS+x} ]; then CLIENT_PROCS="1"; fi
if [ -z ${LOG_INTERVALS+x} ]; then LOG_INTERVALS="100"; fi
if [ -z ${MODEL_NAME+x} ]; then MODEL_NAME="ComplEx"; fi
if [ -z ${SAVE_PATH+x} ]; then SAVE_PATH="ckpts"; fi
if [ -z ${LAUNCHER_CONFIG_PATH+x} ]; then LAUNCHER_CONFIG_PATH="$WORKSPACE/dataset/$DATASET.json"; fi

STARTTIME=$(date +%s)

# launcher instant training workload
if ! [ -z ${DGL_OPERATOR_PHASE_ENV+x} ] && [ $DGL_OPERATOR_PHASE_ENV = "Launcher_Workload" ]
then
    echo "Phase 1/1: launch the training"
    echo "----------"

    python $TRAIN_ENTRY_POINT || \
    { echo "----------" && echo "Phase 1/1 error raised" && exit 1;}

    PHASE1_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 1/1 finished"
    echo "Total : $(($PHASE1_ENDTIME - $STARTTIME)) seconds"
    echo "----------"

# partitioner partitioning workload
elif ! [ -z ${DGL_OPERATOR_PHASE_ENV+x} ] && [ $DGL_OPERATOR_PHASE_ENV = "Partitioner" ]
then
    #########################
    # 1. load and partition #
    #########################
    echo "Phase 1/5: load and partition graph"
    echo "----------"

    #########################
    # 1.1 use dataset FB15k #
    #########################
    if [ -z ${IGNORE_PARTITION+x} ] && [ -z ${CUSTOM_DATASET+x} ]
    then
        echo "Conditions: IGNORE_PARTITION 0, CUSTOM_DATASET 0"
        echo "----------"

        DGLBACKEND=pytorch dglke_partition \
        --dataset $DATASET \
        -k $PARTITIONS \
        --data_path $WORKSPACE/dataset || \
        { echo "----------" && echo "Phase 1/4 error raised" && exit 1;}
    
    ##########################
    # 1.2 use custom dataset #
    ##########################
    elif [ -z ${IGNORE_PARTITION+x} ] && ! [ -z ${CUSTOM_DATASET+x} ]
    then
        echo "Conditions: IGNORE_PARTITION 0, CUSTOM_DATASET 1"
        echo "----------"

        DGLBACKEND=pytorch dglke_partition \
        --dataset $DATASET \
        -k $PARTITIONS \
        --data_path $WORKSPACE/dataset \
        --format $DATASET_FORMAT \
        --data_files $DATASET_FILES || \
        { echo "----------" && echo "Phase 1/4 error raised" && exit 1;}

    fi
    PHASE1_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 1/5 finished"
    echo "Phase : $(($PHASE1_ENDTIME - $STARTTIME)) seconds"
    echo "Total : $(($PHASE1_ENDTIME - $STARTTIME)) seconds"
    echo "----------"

    #########################
    # 2. deliver partitions #
    #########################
    PHASE2_STARTTIME=$(date +%s)
    echo "Phase 2/5: deliver partitions"
    echo "----------"

    ######################################
    # 2.1 deliver partitions to launcher #
    ######################################
    if [ -z ${PVC_PARTITIONED_DIR+x} ]
    then
        python $LAUNCH_ENTRY_POINT \
        --workspace $WORKSPACE \
        --target_dir $WORKSPACE \
        --ip_config "/etc/dgl/leadfile" \
        --cmd_type "copy_batch_container" \
        --container "watcher-loop-partitioner" \
        --source_file_paths "$WORKSPACE/dataset" || \
        { echo "----------" && echo "Phase 2/5 error raised" && exit 1;}
    ##########################################
    # 2.2 deliver partitions to launcher pvc #
    ##########################################
    else
        scp -r "$WORKSPACE/dataset/$DATASET" $PVC_PARTITIONED_DIR
    fi
    PHASE2_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 2/5 finished"
    echo "Phase : $(($PHASE2_ENDTIME - $PHASE2_STARTTIME)) seconds"
    echo "Total : $(($PHASE2_ENDTIME - $STARTTIME)) seconds"
    echo "----------"

# launcher workflow after partitioning
else
    ######################################
    # 3. dispatch partitions by launcher #
    ######################################
    PHASE3_STARTTIME=$(date +%s)
    echo "Phase 3/5: dispatch partitions"
    echo "----------"

    #########################
    # 3.1 use complete copy #
    #########################
    if [ -z ${PVC_PARTITIONED_DIR+x} ]
    then
        python $LAUNCH_ENTRY_POINT \
        --workspace $WORKSPACE \
        --target_dir "$WORKSPACE/dataset" \
        --ip_config "/etc/dgl/hostfile" \
        --cmd_type "copy_batch" \
        --source_file_paths "$WORKSPACE/dataset/$DATASET" || \
        { echo "----------" && echo "Phase 3/5 error raised" && exit 1;}
    
    ###############
    # 3.2 use pvc #
    ###############
    else
        echo "----------"
    fi
    PHASE3_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 3/5 finished"
    echo "Phase : $(($PHASE3_ENDTIME - $PHASE3_STARTTIME)) seconds"
    echo "Total : $(($PHASE3_ENDTIME - $STARTTIME)) seconds"
    echo "----------"

    ########################################
    # 4. revise hostfile in a batch manner #
    ########################################
    PHASE4_STARTTIME=$(date +%s)
    echo "Phase 4/5: batch revise hostfile for DGL"
    echo "----------"

    python $LAUNCH_ENTRY_POINT \
    --ip_config "/etc/dgl/hostfile" \
    --cmd_type "exec_batch" \
    "python $REVISE_HOSTFILE_ENTRY_POINT --workspace $WORKSPACE --ip_config /etc/dgl/hostfile --framework DGLKE" &&
    python $REVISE_HOSTFILE_ENTRY_POINT --workspace $WORKSPACE --ip_config /etc/dgl/hostfile --framework DGLKE || \
    { echo "----------" && echo "Phase 4/5 error raised" && exit 1;}

    PHASE4_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 4/5 finished"
    echo "Phase : $(($PHASE4_ENDTIME - $PHASE4_STARTTIME)) seconds"
    echo "Total : $(($PHASE4_ENDTIME - $STARTTIME)) seconds"
    echo "----------"

    ############
    # 5. trian #
    ############
    PHASE5_STARTTIME=$(date +%s)
    echo "Phase 5/5: launch the training"
    echo "----------"

    ###################################
    # 5.1 train with built-in dataset #
    ###################################
    if [ -z ${CUSTOM_DATASET+x} ]
    then
        echo "Conditions: CUSTOM_DATASET 0"
        echo "----------"

        DGLBACKEND=pytorch dglke_dist_train \
        --path $WORKSPACE \
        --ip_config $WORKSPACE/hostfile_revised \
        --host_config /etc/dgl/hostfile \
        --num_client_proc $CLIENT_PROCS \
        --model_name $MODEL_NAME \
        --dataset $DATASET \
        --data_path $WORKSPACE/dataset \
        --hidden_dim 400 \
        --gamma 143.0 \
        --lr 0.1 \
        --batch_size 1024 \
        --neg_sample_size 256 \
        --max_step 1000 \
        --log_interval $LOG_INTERVALS \
        --batch_size_eval 1024 \
        --test -adv \
        --regularization_coef 1.00E-09 \
        --num_servers $SERVERS \
        --save_path $SAVE_PATH || \
        { echo "----------" && echo "Phase 5/5 error raised" && exit 1;}

    #################################
    # 5.2 train with custom dataset #
    #################################
    else
        echo "Conditions: CUSTOM_DATASET 1"
        echo "----------"

        DGLBACKEND=pytorch dglke_dist_train \
        --path $WORKSPACE \
        --ip_config $WORKSPACE/hostfile_revised \
        --host_config /etc/dgl/hostfile \
        --num_client_proc $CLIENT_PROCS \
        --model_name $MODEL_NAME \
        --dataset $DATASET \
        --data_path $WORKSPACE/dataset \
        --hidden_dim 400 \
        --gamma 143.0 \
        --lr 0.1 \
        --batch_size 1024 \
        --neg_sample_size 256 \
        --max_step 1000 \
        --log_interval $LOG_INTERVALS \
        --batch_size_eval 1024 \
        --test -adv \
        --regularization_coef 1.00E-09 \
        --num_servers $SERVERS \
        --save_path $SAVE_PATH \
        --format $DATASET_FORMAT \
        --data_files $DATASET_FILES || \
        { echo "----------" && echo "Phase 5/5 error raised" && exit 1;}
    fi
    PHASE5_ENDTIME=$(date +%s)
    echo "----------"
    echo "Phase 5/5 finished"
    echo "Phase : $(($PHASE5_ENDTIME - $PHASE5_STARTTIME)) seconds"
    echo "Total : $(($PHASE5_ENDTIME - $STARTTIME)) seconds"
    echo "----------"
fi